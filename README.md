# PHA
The official implementation of the paper "Prototype-based HyperAdapter for Sample-Efficient Multi-task Tuning"
# Training
To run our model in a multi-task setting:

`python finetune_trainer.py ./configs/experiments/glue_t5_base.json`
